# -*- coding: utf-8 -*-
"""GNB_LBW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vCh3BvecQrvmHpi3HDUkOwqohG0g8JE1
"""

import matplotlib.pyplot as plt
from matplotlib import style
import numpy as np
style.use('ggplot')
import pandas as pd

lbw=pd.read_csv('part_1_0.csv')

X = lbw.drop("reslt", axis=1)
X=X.drop("history",axis=1)

y = lbw["reslt"]

import pandas as pd
from sklearn import preprocessing
#normalize
x =X #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
X= pd.DataFrame(x_scaled)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)

"""Calculated Prior Probabilities for the classes"""

def get_count_unique_vals(labels):
  return dict(labels.value_counts())


def prior_prob(labels):
    counts=get_count_unique_vals(labels)
    number_of_instances=labels.count()
    #counts = labels.value_counts().to_dict()
    print(counts.items())
    priors={(key,value/number_of_instances) for key, value in counts.items()}
    #prior_prob={key,value/}
    return priors
    
priors=prior_prob(y_train)
print(priors)

"""Calculate Mean and Variance For all Features"""

import math

def calculate_mean(df):
  return df.mean()
def calculate_std_dev(df):
  return df.std()

def Calculate_Mean_and_Variance(X_train,y_train):
  mean_and_variance_for_class={}
  classes=y_train.unique()
  for everyclass in classes:
      filtered_training_set=X_train[(y_train==everyclass)]
      mean_and_variance=dict()
      for every_attribute in list(X_train.columns.values):
          particular_attribute=filtered_training_set[every_attribute]
          mean_and_variance[every_attribute]=[]
          mean_for_this_attribute=calculate_mean(particular_attribute)
          mean_and_variance[every_attribute].append(mean_for_this_attribute)
          std_dev_for_this_attribute=calculate_std_dev(particular_attribute)
          var_for_this_attribute=math.pow(std_dev_for_this_attribute,2)
          mean_and_variance[every_attribute].append(var_for_this_attribute)
      mean_and_variance_for_class[everyclass]=mean_and_variance
  return mean_and_variance_for_class

dictionary=Calculate_Mean_and_Variance(X_train,y_train)

print((dictionary))

"""NOW using PDF Equation  
Given a feature
"""

def calculate_probability(x, mean, variance):
    exponent = math.exp(-(math.pow(x - mean, 2) / (2 * variance)))
    return (1 / (math.sqrt(2 * math.pi * variance))) * exponent

def predict(X_test,mean_variance):
    predictions = {}
    for _, row in X_test.iterrows():
        #print(_,row)
        results = {}
        for k, v in priors:
            p = 0
            for attr_name in list(X_test.columns.values):
                prob = calculate_probability(row[attr_name], mean_variance[
                    k][attr_name][0], mean_variance[k][attr_name][1])
                if prob > 0:
                    p += math.log(prob)
            results[k] = math.log(v) + p
        predictions[_] = max([key for key in results.keys() if results[
            key] == results[max(results, key=results.get)]])
    return predictions

predictions=predict(X_test,dictionary)

def acc(y_test,prediction):
  count=0
  for ind,row in y_test.iteritems():
    if row == prediction[ind]:
      count+=1
  return count/len(y_test)*100.0

accuracy=acc(y_test,predictions)
print("accuracy",accuracy)
